# -*- coding: utf-8 -*-
"""AMAZON.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/145lGBAjYevxLR-l854AgMiEYzJtUmkRB
"""

!pip install researchpy

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# --- æ­¥éª¤ 2ï¼šç‰¹å¾é€‰æ‹©å’Œç›®æ ‡å˜é‡å®šä¹‰ ---
X = df.drop('price', axis=1, errors='ignore') # Assuming 'price' is the target. Drop it from features if it exists.
y = df['price'] # Target variable

# Identify non-numeric columns
non_numeric_cols = X.select_dtypes(exclude=np.number).columns

# Drop non-numeric columns from X
X = X.drop(columns=non_numeric_cols)

# --- æ­¥éª¤ 3ï¼šåˆ’åˆ†è®­ç»ƒé›†/æµ‹è¯•é›† ---
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# --- æ­¥éª¤ 4ï¼šç‰¹å¾æ ‡å‡†åŒ–ï¼ˆå¾—åˆ° X_train_processedï¼‰---
scaler = StandardScaler()
X_train_processed = scaler.fit_transform(X_train)
X_test_processed = scaler.transform(X_test)

print(f"å¤„ç†åçš„è®­ç»ƒé›†å°ºå¯¸: {X_train_processed.shape}")

# Importer la bibliothÃ¨que pandas
import pandas as pd
import numpy as np

# --- Ã‰TAPE 1 : IMPORTATION DES DONNÃ‰ES ---
# On utilise le chemin d'accÃ¨s complet que vous avez fourni.
file_path = '/content/amazon.csv' # Assuming amazon.csv is the correct file for now.

# NOTE: This cell will be updated later to use the `found_csv_file` from the previous step
# For now, let's assume `df` is loaded correctly.
# If `df` is not already defined, we'll try to load 'amazon.csv'
if 'df' not in locals():
    try:
        df = pd.read_csv(file_path)
        print("âœ… Fichier 'amazon.csv' importÃ© avec succÃ¨s !")
    except FileNotFoundError:
        print(f"âŒ ERREUR : Le fichier n'a pas Ã©tÃ© trouvÃ© au chemin '{file_path}'.")
        print("Veuillez vÃ©rifier que le chemin est correct et que le fichier est bien Ã  cet endroit.")
        # Fallback to general CSV search if amazon.csv is not found
        base_path = '/content/'
        found_csv_file = None
        for root, dirs, files in os.walk(base_path):
            for file in files:
                if file.endswith('.csv'):
                    found_csv_file = os.path.join(root, file)
                    break
            if found_csv_file:
                break
        if found_csv_file:
            print(f"æ­£åœ¨ä»æ–‡ä»¶è¯»å–æ•°æ®: {found_csv_file}")
            df = pd.read_csv(found_csv_file)
        else:
            raise FileNotFoundError("åœ¨æ•°æ®é›†ç›®å½•ä¸­æœªæ‰¾åˆ°ä»»ä½• CSV æ–‡ä»¶ï¼")


# --- Ã‰TAPE 2 : AFFICHAGE ET ANALYSE INITIALE (AVANT LE NETTOYAGE) ---

print("\n" + "="*50)
print(" 1. APERÃ‡U INITIAL DES DONNÃ‰ES (BRUTES)")
print("="*50)

# Affiche les 5 premiÃ¨res lignes
print("\nLes 5 premiÃ¨res lignes :")
print(df.head())

# Affiche les informations sur les colonnes et les types de donnÃ©es
print("\nInformations sur les colonnes (types, non-null count) :")
df.info()

# Affiche les dimensions du dataset (nombre de lignes, nombre de colonnes)
print(f"\nDimensions du dataset initial : {df.shape[0]} lignes et {df.shape[1]} colonnes.")

# VÃ©rifie s'il y a des doublons
nb_doublons = df.duplicated().sum()
print(f"\nNombre de lignes en double trouvÃ©es : {nb_doublons}")

# VÃ©rifie le nombre de valeurs manquantes par colonne
print("\nNombre de valeurs manquantes par colonne :")
print(df.isnull().sum())


# --- Ã‰TAPE 3 : NETTOYAGE DES DONNÃ‰ES ---

print("\n" + "="*50)
print(" 2. DÃ‰BUT DU NETTOYAGE")
print("="*50)

# Gardons une copie des donnÃ©es originales pour comparer
df_cleaned = df.copy()

# 3.1. Gestion des doublons
if nb_doublons > 0:
    print(f"\nSuppression des {nb_doublons} doublons...")
    df_cleaned.drop_duplicates(inplace=True)
    print("âœ… Doublons supprimÃ©s.")
else:
    print("\nâœ… Aucun doublon Ã  supprimer.")

# 3.2. Conversion des types de donnÃ©es pour les colonnes numÃ©riques
print("\nConversion des types de donnÃ©es pour les colonnes numÃ©riques...")

# Function to clean and convert price columns
def clean_price(price_str):
    if isinstance(price_str, str):
        return float(price_str.replace('â‚¹', '').replace(',', '').strip())
    return price_str

# Function to clean and convert discount percentage
def clean_discount(discount_str):
    if isinstance(discount_str, str):
        return float(discount_str.replace('%', '').strip())
    return discount_str

# Function to clean and convert rating count
def clean_rating_count(rating_count_str):
    if isinstance(rating_count_str, str):
        # Handle cases where rating is a string like '|'
        if rating_count_str == '|':
            return np.nan # Or 0, depending on desired imputation
        return int(rating_count_str.replace(',', '').strip())
    return rating_count_str

# Apply cleaning functions to appropriate columns
if 'discounted_price' in df_cleaned.columns:
    df_cleaned['discounted_price'] = df_cleaned['discounted_price'].apply(clean_price)
if 'actual_price' in df_cleaned.columns:
    df_cleaned['actual_price'] = df_cleaned['actual_price'].apply(clean_price)
if 'discount_percentage' in df_cleaned.columns:
    df_cleaned['discount_percentage'] = df_cleaned['discount_percentage'].apply(clean_discount)
if 'rating' in df_cleaned.columns:
    # Some 'rating' values might be non-numeric strings, e.g. '|'
    df_cleaned['rating'] = pd.to_numeric(df_cleaned['rating'], errors='coerce')
if 'rating_count' in df_cleaned.columns:
    df_cleaned['rating_count'] = df_cleaned['rating_count'].apply(clean_rating_count)

print("âœ… Conversion des types de donnÃ©es terminÃ©e.")

# 3.3. Gestion des valeurs manquantes
# SÃ©parer les colonnes numÃ©riques et catÃ©gorielles aprÃ¨s conversion
numeric_cols = df_cleaned.select_dtypes(include=np.number).columns
categorical_cols = df_cleaned.select_dtypes(include=['object', 'category']).columns

print(f"\nColonnes numÃ©riques aprÃ¨s conversion : {list(numeric_cols)}")
print(f"Colonnes catÃ©gorielles aprÃ¨s conversion : {list(categorical_cols)}")

# Imputer les colonnes numÃ©riques avec la moyenne
for col in numeric_cols:
    if df_cleaned[col].isnull().any():
        mean_val = df_cleaned[col].mean()
        print(f"Imputation de la colonne '{col}' avec la moyenne ({mean_val:.2f})")
        df_cleaned[col] = df_cleaned[col].fillna(mean_val)

# Imputer les colonnes catÃ©gorielles avec le mode
for col in categorical_cols:
    if df_cleaned[col].isnull().any():
        mode_val = df_cleaned[col].mode()[0]
        print(f"Imputation de la colonne '{col}' avec le mode ('{mode_val}')")
        df_cleaned[col] = df_cleaned[col].fillna(mode_val)

print("\nâœ… Imputation des valeurs manquantes terminÃ©e.")


# --- Ã‰TAPE 4 : AFFICHAGE ET VÃ‰RIFICATION APRÃˆS NETTOYAGE ---

print("\n" + "="*50)
print(" 3. APERÃ‡U DES DONNÃ‰ES NETTOYÃ‰ES")
print("="*50)

# Affiche les 5 premiÃ¨res lignes du nouveau dataset
print("\nLes 5 premiÃ¨res lignes aprÃ¨s nettoyage :")
print(df_cleaned.head())

# Affiche les informations pour vÃ©rifier qu'il n'y a plus de valeurs manquantes
print("\nInformations aprÃ¨s nettoyage :")
df_cleaned.info()

# Affiche les nouvelles dimensions
print(f"\nDimensions du dataset nettoyÃ© : {df_cleaned.shape[0]} lignes et {df_cleaned.shape[1]} colonnes.")

# VÃ©rification finale : il ne devrait plus y avoir de valeurs manquantes
print("\nVÃ©rification finale des valeurs manquantes :")
print(df_cleaned.isnull().sum())

print("\n" + "="*50)
print(" ğŸ‰ Le nettoyage est terminÃ© ! Votre dataset est prÃªt pour l'analyse. ğŸ‰")
print("="*50)

# Le DataFrame nettoyÃ© est maintenant dans la variable 'df_cleaned'

pip install seaborn scikit-learn

# Importer les bibliothÃ¨ques
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
import numpy as np
import warnings

# --- SUPPRESSION DES AVERTISSEMENTS ---
warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib')
warnings.filterwarnings('ignore', category=FutureWarning)

# DÃ©finir une police par dÃ©faut
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'Helvetica', 'sans-serif']

# --- CRÃ‰ATION DU JEU DE DONNÃ‰ES ---
if 'df_cleaned' not in locals():
    print("CrÃ©ation d'un jeu de donnÃ©es factice pour la dÃ©monstration...")
    from sklearn.datasets import make_regression

    X_reg, y_reg = make_regression(n_samples=200, n_features=1, noise=15, random_state=42)

    df_cleaned = pd.DataFrame()
    df_cleaned['feature_1'] = X_reg.flatten()
    df_cleaned['feature_2'] = y_reg
    df_cleaned['feature_3'] = np.random.randn(200) * 10
    df_cleaned['feature_4'] = df_cleaned['feature_1'] * 2 + np.random.randn(200) * 5

    print("Jeu de donnÃ©es factice crÃ©Ã©.")
    print(f"Colonnes disponibles : {df_cleaned.columns.tolist()}")


# --- 1. MATRICE DE CORRÃ‰LATION ---
print("\n" + "="*50)
print("1. MATRICE DE CORRÃ‰LATION")
print("="*50)

numeric_df = df_cleaned.select_dtypes(include=np.number)
correlation_matrix = numeric_df.corr()

plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=.5)
plt.title('Matrice de Correlation des Variables Numeriques', fontsize=16)
plt.tight_layout()
plt.show()


# --- 2. GRAPHIQUE DE RÃ‰GRESSION LINÃ‰AIRE ---
print("\n" + "="*50)
print("2. RÃ‰GRESSION LINÃ‰AIRE")
print("="*50)

try:
    feature_col = numeric_df.columns[0]
    target_col = numeric_df.columns[1]
    print(f"Utilisation de '{feature_col}' pour prÃ©dire '{target_col}'.")

    plt.figure(figsize=(10, 6))
    sns.regplot(x=feature_col, y=target_col, data=df_cleaned,
                scatter_kws={'alpha':0.5},
                line_kws={'color':'red'})

    plt.title(f'Regression Lineaire : {target_col} vs {feature_col}', fontsize=16)
    plt.xlabel(feature_col)
    plt.ylabel(target_col)
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Calcul des coefficients
    X = df_cleaned[[feature_col]].values
    y = df_cleaned[target_col].values
    model = LinearRegression()
    model.fit(X, y)

    print(f"\nCoefficients de la rÃ©gression linÃ©aire :")
    print(f"  Pente (coefficient) : {model.coef_[0]:.4f}")
    print(f"  OrdonnÃ©e Ã  l'origine : {model.intercept_:.4f}")
    print(f"  RÂ² Score : {model.score(X, y):.4f}")

except IndexError:
    print("ERREUR : Pas assez de colonnes numÃ©riques.")

# Importer les bibliothÃ¨ques
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import make_classification
from matplotlib.patches import Patch
import warnings

# --- SUPPRESSION DES AVERTISSEMENTS ---
warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib')
warnings.filterwarnings('ignore', category=FutureWarning)

# DÃ©finir une police par dÃ©faut
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'Helvetica', 'sans-serif']

# --- CRÃ‰ATION DES DONNÃ‰ES FICTIVES ---
print("="*50)
print("RÃ‰GRESSION LOGISTIQUE")
print("="*50)
print("\nCrÃ©ation des donnÃ©es fictives...")

# GÃ©nÃ©rer des donnÃ©es de classification binaire
X, y = make_classification(
    n_samples=300,           # Nombre d'Ã©chantillons
    n_features=2,            # Nombre de features
    n_redundant=0,           # Pas de features redondantes
    n_informative=2,         # Toutes les features sont informatives
    random_state=42,
    n_clusters_per_class=1,
    class_sep=1.5            # SÃ©paration entre les classes
)

# CrÃ©er un DataFrame
df = pd.DataFrame(X, columns=['Feature_X', 'Feature_Y'])
df['Classe'] = y

print(f"DonnÃ©es crÃ©Ã©es : {len(df)} Ã©chantillons")
print(f"Distribution des classes :")
print(f"  - Classe 0 : {(y == 0).sum()} Ã©chantillons")
print(f"  - Classe 1 : {(y == 1).sum()} Ã©chantillons")

# --- ENTRAÃNEMENT DU MODÃˆLE ---
print("\nEntraÃ®nement du modÃ¨le de rÃ©gression logistique...")

model = LogisticRegression()
model.fit(X, y)

# RÃ©cupÃ©ration des coefficients
w0 = model.coef_[0][0]
w1 = model.coef_[0][1]
b = model.intercept_[0]

print(f"\nCoefficients du modÃ¨le :")
print(f"  w0 (Feature_X) : {w0:.4f}")
print(f"  w1 (Feature_Y) : {w1:.4f}")
print(f"  Intercept (b)  : {b:.4f}")

# --- CRÃ‰ATION DU GRAPHIQUE ---
print("\nGÃ©nÃ©ration du graphique...")

# Limites du graphique
x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1

# Grille pour les zones de dÃ©cision
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),
                     np.arange(y_min, y_max, 0.02))

Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# CrÃ©ation de la figure
plt.figure(figsize=(12, 8))

# Zones de dÃ©cision
plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)

# Points de donnÃ©es
colors = ['blue' if val == 0 else 'red' for val in y]
plt.scatter(X[:, 0], X[:, 1], c=colors, edgecolor='k', s=50, alpha=0.8)

# --- DROITE DE DÃ‰CISION ---
x_line = np.linspace(x_min, x_max, 100)

if abs(w1) > 1e-10:
    y_line = -(w0 * x_line + b) / w1
    mask = (y_line >= y_min) & (y_line <= y_max)
    plt.plot(x_line[mask], y_line[mask], 'k-', linewidth=3, label='Droite de decision')
else:
    x_vertical = -b / w0
    plt.axvline(x=x_vertical, color='k', linewidth=3, label='Droite de decision')

# Ã‰quation sur le graphique
equation_text = f'Equation: {w0:.3f}*X + {w1:.3f}*Y + {b:.3f} = 0'
plt.text(0.02, 0.98, equation_text, transform=plt.gca().transAxes,
         fontsize=11, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

# Accuracy sur le graphique
accuracy = model.score(X, y)
accuracy_text = f'Accuracy: {accuracy:.2%}'
plt.text(0.02, 0.90, accuracy_text, transform=plt.gca().transAxes,
         fontsize=11, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))

# LÃ©gende
legend_elements = [
    Patch(facecolor='blue', edgecolor='k', label='Classe 0'),
    Patch(facecolor='red', edgecolor='k', label='Classe 1'),
    plt.Line2D([0], [0], color='k', linewidth=3, label='Droite de decision')
]
plt.legend(handles=legend_elements, loc='lower right', fontsize=10)

# Titres et labels
plt.title('Regression Logistique avec Droite de Decision', fontsize=16)
plt.xlabel('Feature_X', fontsize=12)
plt.ylabel('Feature_Y', fontsize=12)
plt.xlim(x_min, x_max)
plt.ylim(y_min, y_max)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# --- RÃ‰SUMÃ‰ FINAL ---
print("\n" + "="*50)
print("RÃ‰SUMÃ‰ DU MODÃˆLE")
print("="*50)
print(f"  Ã‰quation de la droite de dÃ©cision :")
print(f"  {w0:.4f} * X + {w1:.4f} * Y + {b:.4f} = 0")
print(f"\n  Accuracy : {accuracy:.2%}")
print("="*50)